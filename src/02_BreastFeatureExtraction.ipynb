{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.feature as feature\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GT_Mask(cropped_gt):\n",
    "    ''' \n",
    "    Finds the contours of the ground truth and creates a binary image per each mass\n",
    "\n",
    "    Arg:\n",
    "      cropped_gt (numpy.ndarray): cropped ground truth image\n",
    "\n",
    "    Output:\n",
    "      vector_gt_mask (list): list that contains one binary image per mass\n",
    "      contours_gt (list): contours of the ground truth\n",
    "    '''\n",
    "\n",
    "    vector_gt_mask = []\n",
    "\n",
    "    contours_gt, _ = cv2.findContours(cropped_gt, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Create a binary mask per mass\n",
    "    for i in range(len(contours_gt)):\n",
    "      mask = np.zeros_like(cropped_gt)\n",
    "      cv2.drawContours(mask, contours_gt, i, (255, 255, 255), cv2.FILLED)\n",
    "      vector_gt_mask.append(mask)\n",
    "\n",
    "    return vector_gt_mask,contours_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_candidate_ROI(image, contour):\n",
    "  ''' \n",
    "  Crops the image to the bounding box containing the contour.\n",
    "\n",
    "  Args:\n",
    "    image (numpy.ndarray): the image to be cropped.\n",
    "    contour (list): the extracted contour from the segmentation\n",
    "  Output:\n",
    "    croppedImg (numpy.ndarray): the cropped image\n",
    "  '''\n",
    "  bbox = cv2.boundingRect(contour)\n",
    "  croppedImg = image[bbox[1]:bbox[1]+bbox[3], bbox[0]:bbox[0]+bbox[2]]\n",
    "  return croppedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_LBP(roi_img, P, R):\n",
    "    ''' \n",
    "    Extracts the histogram of the LBP image for a certain number of neighbours and radius.\n",
    "\n",
    "    Args:\n",
    "        roi_img (numpy.ndarray): the image from which the LBP features will be extracted (cropped ROI)\n",
    "        P (int): number of neighbours\n",
    "        R (int): radius\n",
    "    Output:\n",
    "        hist (numpy.array): histogram of the LBP image\n",
    "    '''\n",
    "    n_points = P * R\n",
    "    lbp_image = local_binary_pattern(roi_img, n_points, R, method='uniform')\n",
    "\n",
    "    # Calculate the histogram of the LBP image\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2), density=True)\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist /= np.sum(hist)\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction for positive images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image number:  0\n",
      "Processing image number:  1\n",
      "Processing image number:  2\n",
      "Processing image number:  3\n",
      "Processing image number:  4\n",
      "Processing image number:  5\n",
      "Processing image number:  6\n",
      "Processing image number:  7\n",
      "Processing image number:  8\n",
      "Processing image number:  9\n",
      "Processing image number:  10\n",
      "Processing image number:  11\n",
      "Processing image number:  12\n",
      "Processing image number:  13\n",
      "Processing image number:  14\n",
      "Processing image number:  15\n",
      "Processing image number:  16\n",
      "Processing image number:  17\n",
      "Processing image number:  18\n",
      "Processing image number:  19\n",
      "Processing image number:  20\n",
      "Processing image number:  21\n",
      "Processing image number:  22\n",
      "Processing image number:  23\n",
      "Processing image number:  24\n",
      "Processing image number:  25\n",
      "Processing image number:  26\n",
      "Processing image number:  27\n",
      "Processing image number:  28\n",
      "Processing image number:  29\n",
      "Processing image number:  30\n",
      "Processing image number:  31\n",
      "Processing image number:  32\n",
      "Processing image number:  33\n",
      "Processing image number:  34\n",
      "Processing image number:  35\n",
      "Processing image number:  36\n",
      "Processing image number:  37\n",
      "Processing image number:  38\n",
      "Processing image number:  39\n",
      "Processing image number:  40\n",
      "Processing image number:  41\n",
      "Processing image number:  42\n",
      "Processing image number:  43\n",
      "Processing image number:  44\n",
      "Processing image number:  45\n",
      "Processing image number:  46\n",
      "Processing image number:  47\n",
      "Processing image number:  48\n",
      "Processing image number:  49\n",
      "Processing image number:  50\n",
      "Processing image number:  51\n",
      "Processing image number:  52\n",
      "Processing image number:  53\n",
      "Processing image number:  54\n",
      "Processing image number:  55\n",
      "Processing image number:  56\n",
      "Processing image number:  57\n",
      "Processing image number:  58\n",
      "Processing image number:  59\n",
      "Processing image number:  60\n",
      "Processing image number:  61\n",
      "Processing image number:  62\n",
      "Processing image number:  63\n",
      "Processing image number:  64\n",
      "Processing image number:  65\n",
      "Processing image number:  66\n",
      "Processing image number:  67\n",
      "Processing image number:  68\n",
      "Processing image number:  69\n",
      "Processing image number:  70\n",
      "Processing image number:  71\n",
      "Processing image number:  72\n",
      "Processing image number:  73\n",
      "Processing image number:  74\n",
      "Processing image number:  75\n",
      "Processing image number:  76\n",
      "Processing image number:  77\n",
      "Processing image number:  78\n",
      "Processing image number:  79\n",
      "Processing image number:  80\n",
      "Processing image number:  81\n",
      "Processing image number:  82\n",
      "Processing image number:  83\n",
      "Processing image number:  84\n",
      "Processing image number:  85\n",
      "Processing image number:  86\n",
      "Processing image number:  87\n",
      "Processing image number:  88\n",
      "Processing image number:  89\n",
      "Processing image number:  90\n",
      "Processing image number:  91\n",
      "Processing image number:  92\n",
      "Processing image number:  93\n",
      "Processing image number:  94\n",
      "Processing image number:  95\n",
      "Processing image number:  96\n",
      "Processing image number:  97\n",
      "Processing image number:  98\n",
      "Processing image number:  99\n",
      "Processing image number:  100\n",
      "Processing image number:  101\n",
      "Processing image number:  102\n",
      "Processing image number:  103\n",
      "Processing image number:  104\n",
      "Processing image number:  105\n",
      "Processing image number:  106\n"
     ]
    }
   ],
   "source": [
    "segmented_images_path = '/Users/clara/Desktop/MAIA/AIA/segmented_images_new/'\n",
    "cropped_images_upsampled_dir = '/Users/clara/Desktop/MAIA/AIA/cropped_imgs_upsampled_all/'\n",
    "cropped_gt_dir = '/Users/clara/Desktop/MAIA/AIA/cropped_gt_all/'\n",
    "\n",
    "num_classes = 11\n",
    "\n",
    "filenames = sorted(file for file in os.listdir(cropped_gt_dir) if file != \".DS_Store\")\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "# Create an empty list to store the dictionaries\n",
    "data = []\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    print(\"Processing image number: \", index)\n",
    "\n",
    "    cropped_gt = cv2.imread(cropped_gt_dir +  filename, cv2.IMREAD_GRAYSCALE)\n",
    "    cropped_img_upsampled = cv2.imread(cropped_images_upsampled_dir+filename, cv2.IMREAD_GRAYSCALE) # this is the raw image (original scale) cropped to only the breast area\n",
    "    \n",
    "    vector_gt_mask, contours_gt = GT_Mask(cropped_gt)\n",
    "\n",
    "    for k in range(len(vector_gt_mask)):\n",
    "        # Threshold the image to convert it to binary format (0 or 255)\n",
    "        _, vector_gt_mask[k] = cv2.threshold(vector_gt_mask[k], 128, 255, cv2.THRESH_BINARY) # to ensure the image is binary\n",
    "        vector_gt_mask[k] = vector_gt_mask[k]/255 # to make the image values be 0 or 1\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            segmented_img = cv2.imread(segmented_images_path+filename[:-4]+\"_\"+str(i)+\".tif\", cv2.IMREAD_GRAYSCALE) # these are the segmented (binary) images for one scale per loop\n",
    "            # Find the contours of the segmented image\n",
    "            contours_segm, _ = cv2.findContours(segmented_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            for j in range(len(contours_segm)):\n",
    "                # Obtain a binary mask for the candidate region\n",
    "                mask_candidate = np.zeros_like(cropped_img_upsampled)\n",
    "                cv2.drawContours(mask_candidate, [contours_segm[j]], 0, (255, 255, 255), cv2.FILLED)\n",
    "                _, mask_candidate = cv2.threshold(mask_candidate, 128, 255, cv2.THRESH_BINARY) # to ensure the image is binary\n",
    "                mask_candidate = mask_candidate / 255 # to make the values be 0 or 1\n",
    "\n",
    "                # Compute the intersection and union images\n",
    "                intersection = cv2.bitwise_and(mask_candidate, vector_gt_mask[k])\n",
    "                union = cv2.bitwise_or(mask_candidate, vector_gt_mask[k])\n",
    "\n",
    "                # Compute the number of white pixels in the intersection and union images\n",
    "                intersection_pixels = cv2.countNonZero(intersection)\n",
    "                union_pixels = cv2.countNonZero(union)\n",
    "\n",
    "                # Compute the IoU\n",
    "                iou = intersection_pixels / union_pixels\n",
    "                \n",
    "                if iou >= 0.5:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "\n",
    "                cropped_boundingBox = crop_candidate_ROI(cropped_img_upsampled, contours_segm[j])\n",
    "\n",
    "                ###### TEXTURE FEATURES ########\n",
    "\n",
    "                # Obtain the GLCM matrix from the bounding box (ROI) for different angles (in radians) and distance offset = 1\n",
    "                graycom = feature.graycomatrix(cropped_boundingBox, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256)\n",
    "\n",
    "                # GLCM FEATURES\n",
    "                contrast = feature.graycoprops(graycom, 'contrast')\n",
    "                dissimilarity = feature.graycoprops(graycom, 'dissimilarity')\n",
    "                homogeneity = feature.graycoprops(graycom, 'homogeneity')\n",
    "                energy = feature.graycoprops(graycom, 'energy')\n",
    "                correlation = feature.graycoprops(graycom, 'correlation')\n",
    "                ASM = feature.graycoprops(graycom, 'ASM')\n",
    "\n",
    "                # LBP FEATURES\n",
    "                hist_LBP_8_1 = extract_LBP(cropped_boundingBox, P = 8, R = 1) # histogram of the LBP image (8, 1)\n",
    "                hist_LBP_16_2 = extract_LBP(cropped_boundingBox, P = 16, R = 2) # histogram of the LBP image (16, 2)\n",
    "\n",
    "                ###### SHAPE FEATURES ########\n",
    "\n",
    "                # Calculate area\n",
    "                area = cv2.contourArea(contours_segm[j])\n",
    "                # Calculate perimeter\n",
    "                perimeter = cv2.arcLength(contours_segm[j], True)\n",
    "                # Calculate circularity\n",
    "                circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "                # Calculate density\n",
    "                density = area / (perimeter ** 2)\n",
    "\n",
    "                ###### GENERAL FEATURES ########\n",
    "                # Create a mask image of zeros with the same shape as the original image\n",
    "                mask = np.zeros_like(cropped_img_upsampled)\n",
    "\n",
    "                # Draw the contour on the mask image\n",
    "                cv2.drawContours(mask, [contours_segm[j]], 0, (255), thickness=cv2.FILLED)\n",
    "\n",
    "                # Apply the mask to the original image to extract the region of interest\n",
    "                roi = cv2.bitwise_and(cropped_img_upsampled, cropped_img_upsampled, mask=mask)\n",
    "\n",
    "                # Calculate the mean intensity and standard deviation within the ROI\n",
    "                mean_intensity = np.mean(roi)\n",
    "                std_deviation = np.std(roi)\n",
    "\n",
    "\n",
    "\n",
    "                # Create a dictionary for the current image\n",
    "                image_data = {}\n",
    "                for p, angle in enumerate([0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "                    image_data[f'Contrast_{angle}'] = contrast[0][p]\n",
    "                    image_data[f'Dissimilarity_{angle}'] = dissimilarity[0][p]\n",
    "                    image_data[f'Homogeneity_{angle}'] = homogeneity[0][p]\n",
    "                    image_data[f'Energy_{angle}'] = energy[0][p]\n",
    "                    image_data[f'Correlation_{angle}'] = correlation[0][p]\n",
    "                    image_data[f'ASM_{angle}'] = ASM[0][p]\n",
    "                image_data['Area'] = area\n",
    "                image_data['Perimeter'] = perimeter\n",
    "                image_data['Circularity'] = circularity\n",
    "                image_data['Density'] = density\n",
    "                image_data['Mean_Intensity'] = mean_intensity\n",
    "                image_data['Std_Dev_Intensity'] = std_deviation\n",
    "\n",
    "\n",
    "                for m in range(len(hist_LBP_8_1)):\n",
    "                    image_data[f'LBP_8_1_{m}'] = hist_LBP_8_1[m]\n",
    "\n",
    "                for m in range(len(hist_LBP_16_2)):\n",
    "                    image_data[f'LBP_16_2_{m}'] = hist_LBP_16_2[m]\n",
    "\n",
    "                image_data['image_id'] = f'{filename}_{k}'\n",
    "              \n",
    "                # Save in a Label column the label that is 1 if candidate has IOU >= 0.2 (if img is positive) and 0 if IOU < 0.2\n",
    "                image_data['Label'] = label\n",
    "                \n",
    "                # Append the dictionary to the list\n",
    "                data.append(image_data)\n",
    "\n",
    "features_df = pd.DataFrame(data)\n",
    "\n",
    "features_df.to_csv('/Users/clara/Desktop/MAIA/AIA/CleanCode/pos_extracted_features_lbp_05.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction for negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image number:  0\n",
      "Processing image number:  1\n",
      "Processing image number:  2\n",
      "Processing image number:  3\n",
      "Processing image number:  4\n",
      "Processing image number:  5\n",
      "Processing image number:  6\n",
      "Processing image number:  7\n",
      "Processing image number:  8\n",
      "Processing image number:  9\n",
      "Processing image number:  10\n",
      "Processing image number:  11\n",
      "Processing image number:  12\n",
      "Processing image number:  13\n",
      "Processing image number:  14\n",
      "Processing image number:  15\n",
      "Processing image number:  16\n",
      "Processing image number:  17\n",
      "Processing image number:  18\n",
      "Processing image number:  19\n",
      "Processing image number:  20\n",
      "Processing image number:  21\n",
      "Processing image number:  22\n",
      "Processing image number:  23\n",
      "Processing image number:  24\n",
      "Processing image number:  25\n",
      "Processing image number:  26\n",
      "Processing image number:  27\n",
      "Processing image number:  28\n",
      "Processing image number:  29\n",
      "Processing image number:  30\n",
      "Processing image number:  31\n",
      "Processing image number:  32\n",
      "Processing image number:  33\n",
      "Processing image number:  34\n",
      "Processing image number:  35\n",
      "Processing image number:  36\n",
      "Processing image number:  37\n",
      "Processing image number:  38\n",
      "Processing image number:  39\n",
      "Processing image number:  40\n",
      "Processing image number:  41\n",
      "Processing image number:  42\n",
      "Processing image number:  43\n",
      "Processing image number:  44\n",
      "Processing image number:  45\n",
      "Processing image number:  46\n",
      "Processing image number:  47\n",
      "Processing image number:  48\n",
      "Processing image number:  49\n",
      "Processing image number:  50\n",
      "Processing image number:  51\n",
      "Processing image number:  52\n",
      "Processing image number:  53\n",
      "Processing image number:  54\n",
      "Processing image number:  55\n",
      "Processing image number:  56\n",
      "Processing image number:  57\n",
      "Processing image number:  58\n",
      "Processing image number:  59\n",
      "Processing image number:  60\n",
      "Processing image number:  61\n",
      "Processing image number:  62\n",
      "Processing image number:  63\n",
      "Processing image number:  64\n",
      "Processing image number:  65\n",
      "Processing image number:  66\n",
      "Processing image number:  67\n",
      "Processing image number:  68\n",
      "Processing image number:  69\n",
      "Processing image number:  70\n",
      "Processing image number:  71\n",
      "Processing image number:  72\n",
      "Processing image number:  73\n",
      "Processing image number:  74\n",
      "Processing image number:  75\n",
      "Processing image number:  76\n",
      "Processing image number:  77\n",
      "Processing image number:  78\n",
      "Processing image number:  79\n",
      "Processing image number:  80\n",
      "Processing image number:  81\n",
      "Processing image number:  82\n",
      "Processing image number:  83\n",
      "Processing image number:  84\n",
      "Processing image number:  85\n",
      "Processing image number:  86\n",
      "Processing image number:  87\n",
      "Processing image number:  88\n",
      "Processing image number:  89\n",
      "Processing image number:  90\n",
      "Processing image number:  91\n",
      "Processing image number:  92\n",
      "Processing image number:  93\n",
      "Processing image number:  94\n",
      "Processing image number:  95\n",
      "Processing image number:  96\n",
      "Processing image number:  97\n",
      "Processing image number:  98\n",
      "Processing image number:  99\n",
      "Processing image number:  100\n",
      "Processing image number:  101\n",
      "Processing image number:  102\n",
      "Processing image number:  103\n",
      "Processing image number:  104\n",
      "Processing image number:  105\n",
      "Processing image number:  106\n",
      "Processing image number:  107\n",
      "Processing image number:  108\n",
      "Processing image number:  109\n",
      "Processing image number:  110\n",
      "Processing image number:  111\n",
      "Processing image number:  112\n",
      "Processing image number:  113\n",
      "Processing image number:  114\n",
      "Processing image number:  115\n",
      "Processing image number:  116\n",
      "Processing image number:  117\n",
      "Processing image number:  118\n",
      "Processing image number:  119\n",
      "Processing image number:  120\n",
      "Processing image number:  121\n",
      "Processing image number:  122\n",
      "Processing image number:  123\n",
      "Processing image number:  124\n",
      "Processing image number:  125\n",
      "Processing image number:  126\n",
      "Processing image number:  127\n",
      "Processing image number:  128\n",
      "Processing image number:  129\n",
      "Processing image number:  130\n",
      "Processing image number:  131\n",
      "Processing image number:  132\n",
      "Processing image number:  133\n",
      "Processing image number:  134\n",
      "Processing image number:  135\n",
      "Processing image number:  136\n",
      "Processing image number:  137\n",
      "Processing image number:  138\n",
      "Processing image number:  139\n",
      "Processing image number:  140\n",
      "Processing image number:  141\n",
      "Processing image number:  142\n",
      "Processing image number:  143\n",
      "Processing image number:  144\n",
      "Processing image number:  145\n",
      "Processing image number:  146\n",
      "Processing image number:  147\n",
      "Processing image number:  148\n",
      "Processing image number:  149\n",
      "Processing image number:  150\n",
      "Processing image number:  151\n",
      "Processing image number:  152\n",
      "Processing image number:  153\n",
      "Processing image number:  154\n",
      "Processing image number:  155\n",
      "Processing image number:  156\n",
      "Processing image number:  157\n",
      "Processing image number:  158\n",
      "Processing image number:  159\n",
      "Processing image number:  160\n",
      "Processing image number:  161\n",
      "Processing image number:  162\n",
      "Processing image number:  163\n",
      "Processing image number:  164\n",
      "Processing image number:  165\n",
      "Processing image number:  166\n",
      "Processing image number:  167\n",
      "Processing image number:  168\n",
      "Processing image number:  169\n",
      "Processing image number:  170\n",
      "Processing image number:  171\n",
      "Processing image number:  172\n",
      "Processing image number:  173\n",
      "Processing image number:  174\n",
      "Processing image number:  175\n",
      "Processing image number:  176\n",
      "Processing image number:  177\n",
      "Processing image number:  178\n",
      "Processing image number:  179\n",
      "Processing image number:  180\n",
      "Processing image number:  181\n",
      "Processing image number:  182\n",
      "Processing image number:  183\n",
      "Processing image number:  184\n",
      "Processing image number:  185\n",
      "Processing image number:  186\n",
      "Processing image number:  187\n",
      "Processing image number:  188\n",
      "Processing image number:  189\n",
      "Processing image number:  190\n",
      "Processing image number:  191\n",
      "Processing image number:  192\n",
      "Processing image number:  193\n",
      "Processing image number:  194\n",
      "Processing image number:  195\n",
      "Processing image number:  196\n",
      "Processing image number:  197\n",
      "Processing image number:  198\n",
      "Processing image number:  199\n",
      "Processing image number:  200\n",
      "Processing image number:  201\n",
      "Processing image number:  202\n",
      "Processing image number:  203\n",
      "Processing image number:  204\n",
      "Processing image number:  205\n",
      "Processing image number:  206\n",
      "Processing image number:  207\n",
      "Processing image number:  208\n",
      "Processing image number:  209\n",
      "Processing image number:  210\n",
      "Processing image number:  211\n",
      "Processing image number:  212\n",
      "Processing image number:  213\n",
      "Processing image number:  214\n",
      "Processing image number:  215\n",
      "Processing image number:  216\n",
      "Processing image number:  217\n",
      "Processing image number:  218\n",
      "Processing image number:  219\n",
      "Processing image number:  220\n",
      "Processing image number:  221\n",
      "Processing image number:  222\n",
      "Processing image number:  223\n",
      "Processing image number:  224\n",
      "Processing image number:  225\n",
      "Processing image number:  226\n",
      "Processing image number:  227\n",
      "Processing image number:  228\n",
      "Processing image number:  229\n",
      "Processing image number:  230\n",
      "Processing image number:  231\n",
      "Processing image number:  232\n",
      "Processing image number:  233\n",
      "Processing image number:  234\n",
      "Processing image number:  235\n",
      "Processing image number:  236\n",
      "Processing image number:  237\n",
      "Processing image number:  238\n",
      "Processing image number:  239\n",
      "Processing image number:  240\n",
      "Processing image number:  241\n",
      "Processing image number:  242\n",
      "Processing image number:  243\n",
      "Processing image number:  244\n",
      "Processing image number:  245\n",
      "Processing image number:  246\n",
      "Processing image number:  247\n",
      "Processing image number:  248\n",
      "Processing image number:  249\n",
      "Processing image number:  250\n",
      "Processing image number:  251\n",
      "Processing image number:  252\n",
      "Processing image number:  253\n",
      "Processing image number:  254\n",
      "Processing image number:  255\n",
      "Processing image number:  256\n",
      "Processing image number:  257\n",
      "Processing image number:  258\n",
      "Processing image number:  259\n",
      "Processing image number:  260\n",
      "Processing image number:  261\n",
      "Processing image number:  262\n",
      "Processing image number:  263\n",
      "Processing image number:  264\n",
      "Processing image number:  265\n",
      "Processing image number:  266\n",
      "Processing image number:  267\n",
      "Processing image number:  268\n",
      "Processing image number:  269\n",
      "Processing image number:  270\n",
      "Processing image number:  271\n",
      "Processing image number:  272\n",
      "Processing image number:  273\n",
      "Processing image number:  274\n",
      "Processing image number:  275\n",
      "Processing image number:  276\n",
      "Processing image number:  277\n",
      "Processing image number:  278\n",
      "Processing image number:  279\n",
      "Processing image number:  280\n",
      "Processing image number:  281\n",
      "Processing image number:  282\n",
      "Processing image number:  283\n",
      "Processing image number:  284\n",
      "Processing image number:  285\n",
      "Processing image number:  286\n",
      "Processing image number:  287\n",
      "Processing image number:  288\n",
      "Processing image number:  289\n",
      "Processing image number:  290\n",
      "Processing image number:  291\n",
      "Processing image number:  292\n",
      "Processing image number:  293\n",
      "Processing image number:  294\n",
      "Processing image number:  295\n",
      "Processing image number:  296\n",
      "Processing image number:  297\n",
      "Processing image number:  298\n",
      "Processing image number:  299\n",
      "Processing image number:  300\n",
      "Processing image number:  301\n",
      "Processing image number:  302\n",
      "Processing image number:  303\n",
      "Processing image number:  304\n",
      "Processing image number:  305\n",
      "Processing image number:  306\n",
      "Processing image number:  307\n",
      "Processing image number:  308\n",
      "Processing image number:  309\n",
      "Processing image number:  310\n",
      "Processing image number:  311\n",
      "Processing image number:  312\n",
      "Processing image number:  313\n",
      "Processing image number:  314\n",
      "Processing image number:  315\n",
      "Processing image number:  316\n",
      "Processing image number:  317\n",
      "Processing image number:  318\n",
      "Processing image number:  319\n",
      "Processing image number:  320\n",
      "Processing image number:  321\n",
      "Processing image number:  322\n",
      "Processing image number:  323\n",
      "Processing image number:  324\n",
      "Processing image number:  325\n",
      "Processing image number:  326\n",
      "Processing image number:  327\n",
      "Processing image number:  328\n",
      "Processing image number:  329\n",
      "Processing image number:  330\n",
      "Processing image number:  331\n",
      "Processing image number:  332\n",
      "Processing image number:  333\n",
      "Processing image number:  334\n",
      "Processing image number:  335\n",
      "Processing image number:  336\n",
      "Processing image number:  337\n",
      "Processing image number:  338\n",
      "Processing image number:  339\n",
      "Processing image number:  340\n",
      "Processing image number:  341\n",
      "Processing image number:  342\n",
      "Processing image number:  343\n",
      "Processing image number:  344\n",
      "Processing image number:  345\n",
      "Processing image number:  346\n",
      "Processing image number:  347\n",
      "Processing image number:  348\n",
      "Processing image number:  349\n",
      "Processing image number:  350\n",
      "Processing image number:  351\n",
      "Processing image number:  352\n",
      "Processing image number:  353\n",
      "Processing image number:  354\n",
      "Processing image number:  355\n",
      "Processing image number:  356\n",
      "Processing image number:  357\n",
      "Processing image number:  358\n",
      "Processing image number:  359\n",
      "Processing image number:  360\n",
      "Processing image number:  361\n",
      "Processing image number:  362\n",
      "Processing image number:  363\n",
      "Processing image number:  364\n",
      "Processing image number:  365\n",
      "Processing image number:  366\n",
      "Processing image number:  367\n",
      "Processing image number:  368\n",
      "Processing image number:  369\n",
      "Processing image number:  370\n",
      "Processing image number:  371\n",
      "Processing image number:  372\n",
      "Processing image number:  373\n",
      "Processing image number:  374\n",
      "Processing image number:  375\n",
      "Processing image number:  376\n",
      "Processing image number:  377\n",
      "Processing image number:  378\n",
      "Processing image number:  379\n",
      "Processing image number:  380\n",
      "Processing image number:  381\n",
      "Processing image number:  382\n",
      "Processing image number:  383\n",
      "Processing image number:  384\n",
      "Processing image number:  385\n",
      "Processing image number:  386\n",
      "Processing image number:  387\n",
      "Processing image number:  388\n",
      "Processing image number:  389\n",
      "Processing image number:  390\n",
      "Processing image number:  391\n",
      "Processing image number:  392\n",
      "Processing image number:  393\n",
      "Processing image number:  394\n",
      "Processing image number:  395\n",
      "Processing image number:  396\n",
      "Processing image number:  397\n",
      "Processing image number:  398\n",
      "Processing image number:  399\n",
      "Processing image number:  400\n",
      "Processing image number:  401\n",
      "Processing image number:  402\n",
      "Processing image number:  403\n",
      "Processing image number:  404\n",
      "Processing image number:  405\n",
      "Processing image number:  406\n",
      "Processing image number:  407\n",
      "Processing image number:  408\n",
      "Processing image number:  409\n"
     ]
    }
   ],
   "source": [
    "segmented_images_path = '/Users/clara/Desktop/MAIA/AIA/segmented_images_new/'\n",
    "cropped_images_upsampled_dir = '/Users/clara/Desktop/MAIA/AIA/cropped_imgs_upsampled_all/'\n",
    "cropped_gt_dir = '/Users/clara/Desktop/MAIA/AIA/cropped_gt_all/'\n",
    "\n",
    "num_classes = 11\n",
    "\n",
    "filenames = sorted(file for file in os.listdir(cropped_images_upsampled_dir) if file != \".DS_Store\")\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "# Create an empty list to store the dictionaries\n",
    "data = []\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    print(\"Processing image number: \", index)\n",
    "    if not os.path.exists(os.path.join(cropped_gt_dir, filename)):\n",
    "        cropped_img_upsampled = cv2.imread(cropped_images_upsampled_dir+filename, cv2.IMREAD_GRAYSCALE) # this is the raw image (original scale) cropped to only the breast area\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            segmented_img = cv2.imread(segmented_images_path+filename[:-4]+\"_\"+str(i)+\".tif\", cv2.IMREAD_GRAYSCALE) # these are the segmented (binary) images for one scale per loop\n",
    "            # Find the contours of the segmented image\n",
    "            contours_segm, _ = cv2.findContours(segmented_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            for j in range(len(contours_segm)):\n",
    "                cropped_boundingBox = crop_candidate_ROI(cropped_img_upsampled, contours_segm[j])\n",
    "\n",
    "                ###### TEXTURE FEATURES ########\n",
    "\n",
    "                # Obtain the GLCM matrix from the bounding box (ROI) for different angles (in radians) and distance offset = 1\n",
    "                graycom = feature.graycomatrix(cropped_boundingBox, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256)\n",
    "\n",
    "                # GLCM FEATURES\n",
    "                contrast = feature.graycoprops(graycom, 'contrast')\n",
    "                dissimilarity = feature.graycoprops(graycom, 'dissimilarity')\n",
    "                homogeneity = feature.graycoprops(graycom, 'homogeneity')\n",
    "                energy = feature.graycoprops(graycom, 'energy')\n",
    "                correlation = feature.graycoprops(graycom, 'correlation')\n",
    "                ASM = feature.graycoprops(graycom, 'ASM')\n",
    "\n",
    "                # LBP FEATURES\n",
    "                hist_LBP_8_1 = extract_LBP(cropped_boundingBox, P = 8, R = 1) # histogram of the LBP image (8, 1)\n",
    "                hist_LBP_16_2 = extract_LBP(cropped_boundingBox, P = 16, R = 2) # histogram of the LBP image (16, 2)\n",
    "\n",
    "                ###### SHAPE FEATURES ########\n",
    "\n",
    "                # Calculate area\n",
    "                area = cv2.contourArea(contours_segm[j])\n",
    "                # Calculate perimeter\n",
    "                perimeter = cv2.arcLength(contours_segm[j], True)\n",
    "                # Calculate circularity\n",
    "                circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "                # Calculate density\n",
    "                density = area / (perimeter ** 2)\n",
    "\n",
    "                ###### GENERAL FEATURES ########\n",
    "                # Create a mask image of zeros with the same shape as the original image\n",
    "                mask = np.zeros_like(cropped_img_upsampled)\n",
    "\n",
    "                # Draw the contour on the mask image\n",
    "                cv2.drawContours(mask, [contours_segm[j]], 0, (255), thickness=cv2.FILLED)\n",
    "\n",
    "                # Apply the mask to the original image to extract the region of interest\n",
    "                roi = cv2.bitwise_and(cropped_img_upsampled, cropped_img_upsampled, mask=mask)\n",
    "\n",
    "                # Calculate the mean intensity and standard deviation within the ROI\n",
    "                mean_intensity = np.mean(roi)\n",
    "                std_deviation = np.std(roi)\n",
    "\n",
    "\n",
    "\n",
    "                # Create a dictionary for the current image\n",
    "                image_data = {}\n",
    "                for p, angle in enumerate([0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "                    image_data[f'Contrast_{angle}'] = contrast[0][p]\n",
    "                    image_data[f'Dissimilarity_{angle}'] = dissimilarity[0][p]\n",
    "                    image_data[f'Homogeneity_{angle}'] = homogeneity[0][p]\n",
    "                    image_data[f'Energy_{angle}'] = energy[0][p]\n",
    "                    image_data[f'Correlation_{angle}'] = correlation[0][p]\n",
    "                    image_data[f'ASM_{angle}'] = ASM[0][p]\n",
    "                image_data['Area'] = area\n",
    "                image_data['Perimeter'] = perimeter\n",
    "                image_data['Circularity'] = circularity\n",
    "                image_data['Density'] = density\n",
    "                image_data['Mean_Intensity'] = mean_intensity\n",
    "                image_data['Std_Dev_Intensity'] = std_deviation\n",
    "\n",
    "\n",
    "                for m in range(len(hist_LBP_8_1)):\n",
    "                    image_data[f'LBP_8_1_{m}'] = hist_LBP_8_1[m]\n",
    "\n",
    "                for m in range(len(hist_LBP_16_2)):\n",
    "                    image_data[f'LBP_16_2_{m}'] = hist_LBP_16_2[m]\n",
    "\n",
    "                label = 0\n",
    "                image_data['image_id'] = f'{filename}'\n",
    "                \n",
    "                # Save in a Label column the label that is 1 if candidate has IOU >= 0.2 (if img is positive) and 0 if IOU < 0.2 or if image is negative\n",
    "                image_data['Label'] = label\n",
    "\n",
    "                # Append the dictionary to the list\n",
    "                data.append(image_data)\n",
    "\n",
    "features_df = pd.DataFrame(data)\n",
    "\n",
    "features_df.to_csv('/Users/clara/Desktop/MAIA/AIA/CleanCode/neg_extracted_features_lbp_02_newImagesID.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features of positive and negative images together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_positives = pd.read_csv('/Users/clara/Desktop/MAIA/AIA/CleanCode/pos_extracted_features_lbp_05.csv')\n",
    "features_negatives = pd.read_csv('/Users/clara/Desktop/MAIA/AIA/CleanCode/neg_extracted_features_lbp_05.csv')\n",
    "\n",
    "# Create a new column called 'Is_Positive' that tells if the feature corresponds to a positive or negative image, to keep track in following performance assessment steps\n",
    "features_positives['Is_Positive'] = 1\n",
    "features_negatives['Is_Positive'] = 0\n",
    "\n",
    "### CONSIDERING ONLY POSITIVE CANDIDATES OF POSITIVE IMAGES AND NEGATIVE CANDIDATES OF NEGATIVE IMAGES\n",
    "# Extract the features from only the positive candidates of the positive images \n",
    "features_positives_only = features_positives[features_positives['Label']==1].copy()\n",
    "# Merge the positive candidates with the negative candidates in a single DataFrame\n",
    "merged_df = pd.concat([features_positives_only, features_negatives], ignore_index=True)\n",
    "\n",
    "### CONSIDERING ALSO THE NEGATIVE CANDIDATES OF POSITIVE IMAGES\n",
    "# Merge the positive candidates with the negative candidates in a single DataFrame\n",
    "# merged_df = pd.concat([features_positives, features_negatives], ignore_index=True)\n",
    "\n",
    "\n",
    "# Select the columns to exclude from scaling\n",
    "exclude_cols = ['image_id', 'Label']\n",
    "\n",
    "# Create a new dataframe with only the columns to be scaled for positive images\n",
    "cols_to_scale = [col for col in merged_df.columns if col not in exclude_cols]\n",
    "scaled_features = merged_df.copy()  \n",
    "scaled_features[cols_to_scale] = MinMaxScaler().fit_transform(merged_df[cols_to_scale])\n",
    "\n",
    "positives = scaled_features[scaled_features['Label']==1].copy()\n",
    "negatives = scaled_features[scaled_features['Label']==0].copy()\n",
    "\n",
    "## CLEAN THE DATAFRAME FOR MACHINE LEARNING STEPS\n",
    "\n",
    "# List of columns to delete\n",
    "columns_to_delete = ['Is_Positive', 'image_id', 'Label']\n",
    "\n",
    "# Delete the specified columns from 'positives' dataframe\n",
    "positives.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "# Delete the specified columns from 'negatives' dataframe\n",
    "negatives.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "print(positives.shape)\n",
    "print(negatives.shape)\n",
    "\n",
    "# Save 'positives' dataframe to CSV without headers\n",
    "positives.to_csv('/Users/clara/Desktop/MAIA/AIA/positives.csv', header=False, index=False)\n",
    "\n",
    "# Save 'negatives' dataframe to CSV without headers\n",
    "negatives.to_csv('/Users/clara/Desktop/MAIA/AIA/negatives.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
